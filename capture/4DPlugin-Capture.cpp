/* --------------------------------------------------------------------------------
 #
 #  4DPlugin-Capture.cpp
 #	source generated by 4D Plugin Wizard
 #	Project : Capture
 #	author : miyako
 #	2019/10/03
 #  
 # --------------------------------------------------------------------------------*/

#include "4DPlugin-Capture.h"

#define USE_VMR9	0

bool request_permission_granted = false;

#if VERSIONWIN
ComInitClass g_ComInitClass;
CaptureMan *captureMan = NULL;
#endif

#if VERSIONMAC
typedef struct {

	NSView *view;
	CALayer *layer;

}addSublayerCtx;

void addSublayer(addSublayerCtx *ctx) {

	[ctx->view.layer addSublayer : ctx->layer];/*main thread only*/

}

@implementation CaptureMan
- (PA_Picture)copyImage
{
	return PA_CreatePicture((void *)&buf[0], (PA_long32)buf.size());
}

-(void)startRunning
{
	if (isConfigured) {
		[previewLayer setHidden : NO];
		[captureSession startRunning];
	}
}

-(void)stopRunning
{
	if (isConfigured) {
		[captureSession stopRunning];
	}
}

-(void)setPreviewLayerView:(NSView *)view frame : (NSRect)frame flipH : (bool)flipH flipV : (bool)flipV
{
	if (isConfigured) {

		if (superLayerView) {
			if (superLayerView != view) {
				[previewLayer removeFromSuperlayer];
			}
		}

		if (flipH) {

			if (!flipV) {
				[previewLayer setAffineTransform : CGAffineTransformMake(-1, 0, 0, 1, frame.size.width, 0)];
			}
			else {
				[previewLayer setAffineTransform : CGAffineTransformMake(-1, 0, 0, -1, 0, 0)];
			}

		}
		else {
			if (flipV) {
				[previewLayer setAffineTransform : CGAffineTransformMake(1, 0, 0, -1, 0, frame.size.height)];
			}
			else {
				[previewLayer setAffineTransform : CGAffineTransformMake(1, 0, 0, 1, 0, 0)];
			}

		}

		if (superLayerView != view) {
			superLayerView = view;
			addSublayerCtx ctx;
			ctx.layer = previewLayer;
			ctx.view = view;
			PA_RunInMainProcess((PA_RunInMainProcessProcPtr)addSublayer, &ctx);
		}

		[previewLayer setFrame : frame];
	}
}

-(void)updatePreviewLayerFrame:(NSRect)frame flipH : (bool)flipH flipV : (bool)flipV hidden : (bool)hidden
{
	if (isConfigured) {

		if (flipH) {

			if (!flipV) {
				[previewLayer setAffineTransform : CGAffineTransformMake(-1, 0, 0, 1, frame.size.width, 0)];
			}
			else {
				[previewLayer setAffineTransform : CGAffineTransformMake(-1, 0, 0, -1, 0, 0)];
			}

		}
		else {
			if (flipV) {
				[previewLayer setAffineTransform : CGAffineTransformMake(1, 0, 0, -1, 0, frame.size.height)];
			}
			else {
				[previewLayer setAffineTransform : CGAffineTransformMake(1, 0, 0, 1, 0, 0)];
			}

		}

		[previewLayer setHidden : hidden];
		[previewLayer setFrame : frame];
	}

}

-(void)startRecording:(NSURL *)url
{
	if (isConfigured) {
		if (isConfigured) {
			if (![fileOutput isRecording]) {
				[fileOutput startRecordingToOutputFileURL : url recordingDelegate : self];

			}
		}
	}
}

-(void)stopRecording
{
	if (isConfigured) {
		[fileOutput stopRecording];
	}

}

-(void)pauseRecording
{
	if (isConfigured) {
		[fileOutput pauseRecording];
	}
}

-(void)resumeRecording
{
	if (isConfigured) {
		[fileOutput resumeRecording];
	}
}

-(bool)isDeviceUniqueID:(const char *)uniqueID
{
	bool returnValue = false;

	if (uniqueID) {

		returnValue = [[NSString stringWithUTF8String : uniqueID]isEqualToString:deviceUniqueID];
	}

	return returnValue;
}

-(id)initWithUniqueID:(const char *)uniqueID
{
	if (!(self = [super init])) return self;

	NSError *error = nil;

	captureSession = [[AVCaptureSession alloc]init];

	[captureSession beginConfiguration];

	if (!uniqueID) {

		videoDevice = [AVCaptureDevice defaultDeviceWithMediaType : AVMediaTypeVideo];
		deviceUniqueID = [videoDevice uniqueID];

	}
	else {
		deviceUniqueID = [NSString stringWithUTF8String : uniqueID];
		videoDevice = [AVCaptureDevice deviceWithUniqueID : deviceUniqueID];
	}

	videoInput = [AVCaptureDeviceInput deviceInputWithDevice : videoDevice error : &error];

	if (videoInput) {
		if ([captureSession canAddInput : videoInput]) {
			[captureSession addInput : videoInput];
			videoOutput = [[AVCaptureVideoDataOutput alloc]init];
			if (videoOutput) {
				if ([captureSession canAddOutput : videoOutput]) {
					[captureSession addOutput : videoOutput];

					imageOutput = [[AVCaptureStillImageOutput alloc]init];
					if (imageOutput) {

						if ([captureSession canAddOutput : imageOutput])
						{
							[captureSession addOutput : imageOutput];

							fileOutput = [[AVCaptureMovieFileOutput alloc]init];
							if (fileOutput) {
								if ([captureSession canAddOutput : fileOutput])
									[captureSession addOutput : fileOutput];

								previewLayer = [[AVCaptureVideoPreviewLayer alloc]init];

								/* no combination to emulate 4D resizing (y is pinned to the bottom, not top) */
								//                            previewLayer.autoresizingMask = kCALayerWidthSizable|kCALayerHeightSizable;
								[previewLayer setSession : captureSession];

								superLayerView = nil;

								imageCaptured = false;
								isConfigured = true;
							}
						}
					}
				}
			}
		}
	}

	[captureSession commitConfiguration];

	notificationCenter = [NSNotificationCenter defaultCenter];

	if (@available(macOS 10.14, *)) {
	[notificationCenter
		addObserver : self
		selector : @selector(onInterrupted : )
				   name:AVCaptureSessionWasInterruptedNotification
		object : nil];

	[notificationCenter
		addObserver : self
		selector : @selector(onSessionInterruptionEnded : )
				   name:AVCaptureSessionInterruptionEndedNotification
		object : nil];
	}

	[notificationCenter
		addObserver : self
		selector : @selector(onSessionRuntimeError : )
				   name:AVCaptureSessionRuntimeErrorNotification
		object : nil];

	[notificationCenter
		addObserver : self
		selector : @selector(onStartRunning : )
				   name:AVCaptureSessionDidStartRunningNotification
		object : nil];

	[notificationCenter
		addObserver : self
		selector : @selector(onStopRunning : )
				   name:AVCaptureSessionDidStopRunningNotification
		object : nil];

	[notificationCenter
		addObserver : self
		selector : @selector(onDeviceConnected : )
				   name:AVCaptureDeviceWasConnectedNotification
		object : nil];

	[notificationCenter
		addObserver : self
		selector : @selector(onDeviceDisconnected : )
				   name:AVCaptureDeviceWasDisconnectedNotification
		object : nil];

	return self;
}

-(void)onDeviceDisconnected:(NSNotification *)notification
{

}

-(void)onDeviceConnected : (NSNotification *)notification
{

}

-(void)onStopRunning : (NSNotification *)notification
{
	if ([fileOutput isRecording])[fileOutput stopRecording];
}

-(void)onStartRunning : (NSNotification *)notification
{
    /* none these work convincingly; use redraw window inside 4D */
    
//    [[superLayerView window] display];
    [superLayerView updateLayer];
    [[superLayerView window] update];
//    [[superLayerView window] setViewsNeedDisplay:YES];
}

-(void)onSessionRuntimeError : (NSNotification *)notification
{
	if ([fileOutput isRecording])[fileOutput stopRecording];
}

-(void)onSessionInterruptionEnded : (NSNotification *)notification
{

}

-(void)onInterrupted : (NSNotification *)notification
{

}

-(void)captureOutput : (AVCaptureFileOutput *)output
didStartRecordingToOutputFileAtURL : (NSURL *)fileURL
	fromConnections : (NSArray<AVCaptureConnection *> *)connections
{

}

-(void)captureOutput : (AVCaptureFileOutput *)output
willFinishRecordingToOutputFileAtURL : (NSURL *)fileURL
	fromConnections : (NSArray<AVCaptureConnection *> *)connections
	error : (NSError *)error
{

}

-(void)captureOutput : (AVCaptureFileOutput *)output
didFinishRecordingToOutputFileAtURL : (NSURL *)outputFileURL
	fromConnections : (NSArray<AVCaptureConnection *> *)connections
	error : (NSError *)error
{

}

-(void)captureOutput : (AVCaptureFileOutput *)output
didPauseRecordingToOutputFileAtURL : (NSURL *)fileURL
	fromConnections : (NSArray<AVCaptureConnection *> *)connections
{

}

-(void)captureOutput : (AVCaptureFileOutput *)output
didResumeRecordingToOutputFileAtURL : (NSURL *)fileURL
	fromConnections : (NSArray<AVCaptureConnection *> *)connections
{

}

-(bool)isImageReady
{
	return imageCaptured;
}

-(void)prepareForCaptureImage
{
	imageCaptured = false;
}

-(void)captureImage
{
	if (isConfigured) {

		if ([captureSession isRunning]) {

			AVCaptureConnection *connection = [imageOutput connectionWithMediaType : AVMediaTypeVideo];

			[imageOutput captureStillImageAsynchronouslyFromConnection : connection
				completionHandler : ^ (CMSampleBufferRef imageDataSampleBuffer, NSError *error)
			{

				if (!error)
				{
					NSData *data = [AVCaptureStillImageOutput jpegStillImageNSDataRepresentation : imageDataSampleBuffer];
					if (data) {
						buf.resize([data length]);
						[data getBytes : &buf[0] length : [data length]];
					}
				}

				imageCaptured = true;
			}];
		}
		else {
			imageCaptured = true;
		}
	}
	else {
		imageCaptured = true;
	}
}

-(void)dealloc
{
	[notificationCenter removeObserver : self];

	if (isConfigured) {

		if ([fileOutput isRecording])[fileOutput stopRecording];

		[previewLayer release];
		[videoOutput release];
		[imageOutput release];
		[fileOutput release];
	}

	[captureSession release];

	[super dealloc];
}
@end

CaptureMan *captureMan = nil;

#endif

void OnStartup()
{

}

void OnExit()
{
#if VERSIONMAC
    if(captureMan)
    {
        [captureMan release];
        captureMan = nil;
    }
#else
	if (captureMan)
	{
		delete captureMan;
		captureMan = NULL;
	}
#endif
}

#pragma mark -

void PluginMain(PA_long32 selector, PA_PluginParameters params) {
    
	try
	{
        switch(selector)
        {
            case kInitPlugin :
            case kServerInitPlugin :
                OnStartup();
                break;
                
            case kDeinitPlugin:
            case kServerDeinitPlugin:
                OnExit();
                break;
                
			// --- Capture
            
			case 1 :
				capture_Request_permisson(params);
				break;

            case 2 :
                capture_Start(params);
                break;
                
            case 3 :
                capture_Stop(params);
                break;
                
            case 4 :
                capture_Image(params);
                break;
                
            case 5 :
                capture_Update(params);
                break;
                
            case 6 :
                capture_Start_recording(params);
                break;
                
            case 7 :
                capture_Stop_recording(params);
                break;
                
            case 8 :
                capture_Pause_recording(params);
                break;
                
            case 9 :
                capture_Resume_recording(params);
                break;
                
            case 10 :
                capture_Devices(params);
                break;
  
        }

	}
	catch(...)
	{

	}
}

#pragma mark -

#if VERSIONMAC
NSWindow *getWindow(PA_long32 w) {
    
    //EX_GET_HWND has been fixed in 15R3 to return a NSWindow* on mac 64bit.
    //http://forums.4d.fr/Post/EN/15872830/1/17032044
    
    PA_ulong32 version = (PA_Get4DVersion/*threadSafe*/() & 0x0000FFFF);
    //    int minor = version & 0x000F;
    int r = (version & 0x00F0) >> 4;
    int major = (version & 0xFF00) >> 8;
    if (((major >=0x15) && (r >= 3)) || (major >=0x16))
    {
        return (NSWindow *)PA_GetWindowPtr(reinterpret_cast<NSWindow *>(w));
    }
    
    return 0;
}
#endif

void capture_Image(PA_PluginParameters params) {
#if VERSIONMAC
	if (request_permission_granted) {
		if (captureMan)
		{
			[captureMan prepareForCaptureImage];
			[captureMan performSelectorInBackground : @selector(captureImage) withObject:nil];

			do {
				PA_YieldAbsolute();
			} while (![captureMan isImageReady]);

			PA_Picture p = [captureMan copyImage];
			PA_ReturnPicture(params, p);
		}
	}
#else
	if (captureMan) {
		PA_Picture p = captureMan->copyImage();
		PA_ReturnPicture(params, p);
	}

	
#endif
}

void capture_Stop(PA_PluginParameters params) {
 
#if VERSIONMAC
    
    if(request_permission_granted) {
        if(captureMan)
        {
            [captureMan performSelectorInBackground:@selector(stopRunning) withObject:nil];
        }
    }
#else
	if (captureMan) {
		captureMan->stopRunning();
	}
#endif
}

void capture_Update(PA_PluginParameters params) {

#if VERSIONMAC
    if(request_permission_granted) {
        
        if(captureMan)
        {
            PA_ObjectRef param = PA_GetObjectParameter(params, 1);
            
            if(param) {
                
                PA_long32 x = (PA_long32)ob_get_n(param, L"x");
                PA_long32 y = (PA_long32)ob_get_n(param, L"y");
                PA_long32 width = (PA_long32)ob_get_n(param, L"width");
                PA_long32 height = (PA_long32)ob_get_n(param, L"height");
                
                bool flipV = ob_get_b(param, L"flipV");
                bool flipH = ob_get_b(param, L"flipH");
                bool hidden = ob_get_b(param, L"hidden");
                
                NSRect rect;
                rect.origin.x = x;
                rect.origin.y = y;
                rect.size.width = width;
                rect.size.height = height;
                
                [captureMan updatePreviewLayerFrame:rect flipH:flipH flipV:flipV hidden:hidden];
            }
        }
    }
    
#else
    PA_ObjectRef param = PA_GetObjectParameter(params, 1);
    
    if(param) {
        
		//PA_long32 w = (PA_long32)ob_get_n(param, L"window");
        PA_long32 x = (PA_long32)ob_get_n(param, L"x");
        PA_long32 y = (PA_long32)ob_get_n(param, L"y");
        PA_long32 width = (PA_long32)ob_get_n(param, L"width");
        PA_long32 height = (PA_long32)ob_get_n(param, L"height");

        bool hidden = ob_get_b(param, L"hidden");
       
		if (captureMan) {
			captureMan->update(0, x, y, width, height, hidden);
		}

    }
    
#endif
}

void capture_Start_recording(PA_PluginParameters params) {
    
#if VERSIONMAC
    if(request_permission_granted) {
        
        PA_ObjectRef param = PA_GetObjectParameter(params, 1);
        
        if(param) {
            
            CUTF8String path;
            ob_get_s(param, L"file", &path);
            NSString *str = [[NSString alloc]initWithUTF8String:(const char *)path.c_str()];
            
            if(str) {
                NSURL *url = (NSURL *)CFURLCreateWithFileSystemPath(kCFAllocatorDefault, (CFStringRef)str, kCFURLHFSPathStyle, false);
                [captureMan performSelectorInBackground:@selector(startRecording:) withObject:url];
                [url release];
                [str release];
            }
        }
    }
    
#endif
}

void capture_Pause_recording(PA_PluginParameters params) {
    
#if VERSIONMAC
    if(request_permission_granted) {
        [captureMan performSelectorInBackground:@selector(pauseRecording) withObject:nil];
    }
    
#endif
}

void capture_Resume_recording(PA_PluginParameters params) {
    
#if VERSIONMAC
    if(request_permission_granted) {
        [captureMan performSelectorInBackground:@selector(resumeRecording) withObject:nil];
    }
    
#endif
}

void capture_Stop_recording(PA_PluginParameters params) {

#if VERSIONMAC
    
    if(request_permission_granted) {
        [captureMan performSelectorInBackground:@selector(stopRecording) withObject:nil];
    }
    
#endif
}

void capture_Start(PA_PluginParameters params) {
    
#if VERSIONMAC
    
    if(request_permission_granted) {
        
        PA_ObjectRef param = PA_GetObjectParameter(params, 1);
        
        if(param) {
            
            PA_long32 w = (PA_long32)ob_get_n(param, L"window");
            NSWindow *window = getWindow(w);
            
            PA_long32 x = (PA_long32)ob_get_n(param, L"x");
            PA_long32 y = (PA_long32)ob_get_n(param, L"y");
            PA_long32 width = (PA_long32)ob_get_n(param, L"width");
            PA_long32 height = (PA_long32)ob_get_n(param, L"height");
            
            bool flipV = ob_get_b(param, L"flipV");
            bool flipH = ob_get_b(param, L"flipH");
            
            bool force = ob_get_b(param, L"force");
            
            const char *uniqueID = NULL;
            CUTF8String _uniqueID;
            
            if(ob_get_s(param, L"device", &_uniqueID)) {
                uniqueID = (const char *)_uniqueID.c_str();
            }
            
            if(window) {
                
                NSView *contentView = [window contentView];
                
                if(!captureMan)
                {

                    captureMan = [[CaptureMan alloc]initWithUniqueID:uniqueID];
                    force = false;/* captureMan is not instantiated yet */
                    
                }else if((uniqueID) && (![captureMan isDeviceUniqueID:uniqueID])) {
                    force = true;/* uniqueID changed; force */
                }/* on mac we can chenge window without force */

                if(force) {
                    
                    [captureMan release];
                    captureMan = [[CaptureMan alloc]initWithUniqueID:uniqueID];
                    
                }
                
                NSRect rect;
                rect.origin.x = x;
                rect.origin.y = y;
                rect.size.width = width;
                rect.size.height = height;
                
                [captureMan setPreviewLayerView:contentView frame:rect flipH:flipH flipV:flipV];
                
                [captureMan performSelectorInBackground:@selector(startRunning) withObject:nil];
                
            }
        }
    }

#else
    PA_ObjectRef param = PA_GetObjectParameter(params, 1);
    
    if(param) {
        
        PA_long32 w = (PA_long32)ob_get_n(param, L"window");

		PA_long32 x = (PA_long32)ob_get_n(param, L"x");
		PA_long32 y = (PA_long32)ob_get_n(param, L"y");
		PA_long32 width = (PA_long32)ob_get_n(param, L"width");
		PA_long32 height = (PA_long32)ob_get_n(param, L"height");

        bool force = ob_get_b(param, L"force");
        
        const wchar_t *uniqueID = NULL;
        CUTF16String _uniqueID;
        
        if(ob_get_a(param, L"device", &_uniqueID)) {
            uniqueID = (const wchar_t *)_uniqueID.c_str();
        }

		const wchar_t *file = NULL;
		CUTF16String _file;

		if (ob_get_a(param, L"file", &_file)) {
			file = (const wchar_t *)_file.c_str();
		}

		if (!captureMan)
		{
			captureMan = new CaptureMan();
			captureMan->setup(uniqueID, w, x, y, width, height, file);
            force = false;/* captureMan is not instantiated yet */
		}
		else
		{
			if ((w) && (captureMan->isWindowRef(w))) {
                force = true;/* window changed; force */
            } else if ((uniqueID) && !(captureMan->isDeviceUniqueID(uniqueID))) {
                force = true;/* uniqueID changed; force */
            } else {
                force = false;
				captureMan->update(w, x, y, width, height, false);
			}

		}
        
        if(force) {
            delete captureMan;
            captureMan = new CaptureMan();
            captureMan->setup(uniqueID, w, x, y, width, height, file);
        }

		captureMan->startRunning();
    }

#endif
}

#if VERSIONMAC
request_permission_t requestPermission(AVMediaType mediaType) {

	if (@available(macOS 10.14, *)) {

	switch ([AVCaptureDevice authorizationStatusForMediaType : mediaType])
	{
	case AVAuthorizationStatusAuthorized:
		request_permission_granted = true;
		return request_permission_authorized;
		break;

	case AVAuthorizationStatusNotDetermined:
		[AVCaptureDevice requestAccessForMediaType : mediaType completionHandler : ^ (BOOL granted) {
			if (granted) {
				request_permission_granted = true;
			}
		}];
		return request_permission_not_determined;
		break;

	case AVAuthorizationStatusDenied:
		request_permission_granted = false;
		return request_permission_denied;
		break;

	case AVAuthorizationStatusRestricted:
		request_permission_granted = false;
		return request_permission_restricted;
		break;
	}
	}

	return request_permission_unknown;
}

#endif

/*
 https://stackoverflow.com/questions/18970093/can-an-ios-app-read-its-own-entitlements-at-runtime
 */

void capture_Request_permisson(PA_PluginParameters params) {
    
    PA_ObjectRef status = PA_CreateObject();
    
#if VERSIONMAC
    NSBundle *mainBundle = [NSBundle mainBundle];
    if(mainBundle) {
      NSDictionary *infoDictionary = [mainBundle infoDictionary];
        if(infoDictionary) {
            NSString *cameraUsageDescription = [infoDictionary objectForKey:@"NSCameraUsageDescription"];
            if(cameraUsageDescription) {
    
                SecTaskRef sec = SecTaskCreateFromSelf(kCFAllocatorMalloc);
                CFErrorRef err = nil;
                CFBooleanRef boolValue = (CFBooleanRef)SecTaskCopyValueForEntitlement(
                                                                                      SecTaskCreateFromSelf(NULL), CFSTR("com.apple.security.device.camera"), &err);
                if(!err) {
                    
                    if(boolValue) {
                        
                        if(CFBooleanGetValue(boolValue)) {
                            request_permission_t permission = requestPermission(AVMediaTypeVideo);
                            switch (permission) {
                                    
                                case request_permission_authorized:
                                    ob_set_b(status, L"success", true);
                                    break;
                                    
                                case request_permission_denied:
                                    ob_set_b(status, L"success", false);
                                    ob_set_s(status, L"errorMessage", "permission denied");
                                    break;
                                    
                                case request_permission_restricted:
                                    ob_set_b(status, L"success", false);
                                    ob_set_s(status, L"errorMessage", "permission restricted");
                                    break;
                                
                                case request_permission_not_determined:
                                    ob_set_b(status, L"success", false);
                                    ob_set_s(status, L"errorMessage", "permission not determined");
                                    break;
                                    
                                default:
                                    break;
                            }
                        }
                        
                        if(request_permission_granted) {
                            ob_set_b(status, L"success", true);
                        }
                        
                        CFRelease(boolValue);
                    }else{
                        ob_set_b(status, L"success", false);
                        ob_set_s(status, L"errorMessage", "com.apple.security.device.camera is set to false in app entitlement");
                    }
                    
                }else{
                    ob_set_b(status, L"success", false);
                    ob_set_s(status, L"errorMessage", "com.apple.security.device.camera is missing in app entitlement");
                }
                
                CFRelease(sec);
  
            }else{
                ob_set_b(status, L"success", false);
                ob_set_s(status, L"errorMessage", "NSCameraUsageDescription is missing in app info.plist");
            }
        }else{
            ob_set_b(status, L"success", false);
            ob_set_s(status, L"errorMessage", "failed to locate [mainBundle infoDictionary]");
        }
    }else{
        ob_set_b(status, L"success", false);
        ob_set_s(status, L"errorMessage", "failed to locate [NSBundle mainBundle]");
    }
#endif
    
    PA_ReturnObject(params, status);
}

void capture_Devices(PA_PluginParameters params) {
    
    PA_CollectionRef devices = PA_CreateCollection();
    
#if VERSIONMAC
    NSArray<AVCaptureDevice *> *_devices = [AVCaptureDevice devices];
    
    [_devices enumerateObjectsUsingBlock:^(AVCaptureDevice *
                                           _device, NSUInteger idx, BOOL *stop){
        
        if([_device hasMediaType:AVMediaTypeVideo]) {
            
            NSString *uniqueID = [_device uniqueID];
            NSString *modelID = [_device modelID];
            NSString *manufacturer = [_device manufacturer];
            NSString *localizedName = [_device localizedName];
            BOOL connected = [_device isConnected];
            
            PA_ObjectRef o = PA_CreateObject();
            
            ob_set_s(o, L"uniqueID", (const char *)[uniqueID UTF8String]);
            ob_set_s(o, L"modelID", (const char *)[modelID UTF8String]);
            ob_set_s(o, L"manufacturer", (const char *)[manufacturer UTF8String]);
            ob_set_s(o, L"localizedName", (const char *)[localizedName UTF8String]);
            ob_set_b(o, L"connected", connected);
            
            PA_Variable v = PA_CreateVariable(eVK_Object);
            PA_SetObjectVariable(&v, o);
            
            PA_SetCollectionElement(devices, PA_GetCollectionLength(devices), v);
            
        }
        
    }];
#else
    if(g_ComInitClass.isComReady()) {
        
        ICreateDevEnum *pDevEnum = NULL;
        HRESULT hr = CoCreateInstance(CLSID_SystemDeviceEnum,
                                      NULL,
                                      CLSCTX_INPROC_SERVER,
                                      IID_PPV_ARGS(&pDevEnum));
        
        if (SUCCEEDED(hr))
        {
            IEnumMoniker *pEnum = NULL;
            hr = pDevEnum->CreateClassEnumerator(CLSID_VideoInputDeviceCategory, &pEnum, 0);
            
            if (hr != S_FALSE)
            {
                IMoniker *pMoniker = NULL;
                while (pEnum->Next(1, &pMoniker, NULL) == S_OK)
                {
                    IPropertyBag *pPropBag = NULL;
                    hr = pMoniker->BindToStorage(0, 0, IID_PPV_ARGS(&pPropBag));
                    
                    if (FAILED(hr))
                    {
                        pMoniker->Release();
                        continue;
                    }
                    
                    VARIANT var;
                    
                    PA_ObjectRef o = PA_CreateObject();
                    
                    VariantInit(&var);
                    hr = pPropBag->Read(L"FriendlyName", &var, 0);
                    if (SUCCEEDED(hr))
                    {
                        ob_set_a(o, L"friendlyName", (const wchar_t *)var.bstrVal);
                        VariantClear(&var);
                    }

                    VariantInit(&var);
                    hr = pPropBag->Read(L"Description", &var, 0);
                    if (SUCCEEDED(hr))
                    {
                        ob_set_a(o, L"description", (const wchar_t *)var.bstrVal);
                        VariantClear(&var);
                    }
                    
                    VariantInit(&var);
                    hr = pPropBag->Read(L"DevicePath", &var, 0);
                    if (SUCCEEDED(hr))
                    {
                        ob_set_a(o, L"devicePath", (const wchar_t *)var.bstrVal);
                        VariantClear(&var);
                    }
                    
                    PA_Variable v = PA_CreateVariable(eVK_Object);
                    PA_SetObjectVariable(&v, o);
                    PA_SetCollectionElement(devices, PA_GetCollectionLength(devices), v);
                    
                    pPropBag->Release();
                    pMoniker->Release();
                }
                
            }
            pDevEnum->Release();
        }
    }
    
#endif
    
    PA_ReturnCollection(params, devices);
}

#if VERSIONWIN

 bool CaptureMan::isWindowRef(PA_long32 w) {

     bool returnValue = false;
     
     if (isConfigured) {
         returnValue = (windowRef == w);
     }

	return returnValue;
}

bool CaptureMan::isDeviceUniqueID(const wchar_t *uniqueID) {

	bool returnValue = false;

	if (uniqueID) {
		std::wstring u = (const wchar_t *)uniqueID;
		if (isConfigured) {

			returnValue = (devicePath.compare(u) == 0);

		}
	
	}

	return returnValue;
}

void CaptureMan::startRunning() {

	if (isConfigured) {

		if (!USE_VMR9) {
			videoWindow->put_Visible(OAFALSE);
			videoWindow->put_AutoShow(OATRUE);
			sampleGrabber->SetBufferSamples(TRUE);
		}

		mediaControl->Run();
	}

}

void CaptureMan::stopRunning() {

	if (isConfigured) {

		if (!USE_VMR9) {
			sampleGrabber->SetBufferSamples(FALSE);
			videoWindow->put_Visible(OAFALSE);
			videoWindow->put_AutoShow(OAFALSE);
		}

		mediaControl->Stop();
	}

}

CaptureMan::CaptureMan() {

	isConfigured = false;

	fileFilter = NULL;
	sinkFilter = NULL;
	captureGraphBuilder = NULL;
	videoWindow = NULL;
	mediaControl = NULL;
	videoControl = NULL;
	sampleGrabber = NULL;
	grabberFilter = NULL;
	graphBuilder = NULL;
	deviceFilter = NULL;

	windowlessControl9 = NULL;
	filterConfig9 = NULL;
	vmr9Filter = NULL;
}

CaptureMan::~CaptureMan() {

	if (fileFilter) fileFilter->Release();
	if (sinkFilter) sinkFilter->Release();

	if (captureGraphBuilder) captureGraphBuilder->Release();
	if (videoWindow) {
		videoWindow->put_Visible(OAFALSE);
		videoWindow->put_AutoShow(OAFALSE);
		videoWindow->SetWindowPosition(0, 0, 0, 0);
		videoWindow->put_Owner(NULL);
		videoWindow->Release();
	}
	if (mediaControl) {
		mediaControl->Stop();
		mediaControl->Release();
	}
	if (sampleGrabber) {
		sampleGrabber->SetBufferSamples(FALSE);
		sampleGrabber->Release();
	}
	if (videoControl) {
		videoControl->Release();
	}
	if (grabberFilter) grabberFilter->Release();
	if (graphBuilder) graphBuilder->Release();
	if (deviceFilter) deviceFilter->Release();

	if (windowlessControl9) windowlessControl9->Release();
	if (filterConfig9) filterConfig9->Release();
	if (vmr9Filter) vmr9Filter->Release();

	fileFilter = NULL;
	sinkFilter = NULL;
	captureGraphBuilder = NULL;
	videoWindow = NULL;
	mediaControl = NULL;
	videoControl = NULL;
	sampleGrabber = NULL;
	grabberFilter = NULL;
	graphBuilder = NULL;
	deviceFilter = NULL;

	windowlessControl9 = NULL;
	filterConfig9 = NULL;
	vmr9Filter = NULL;
}

IBaseFilter *capture_getDeviceForName(const wchar_t *n, std::wstring &devicePath) {

	IBaseFilter *pBFilter = NULL;

	std::wstring deviceName;

	if (n) {
		deviceName = std::wstring(n);
	}

	ICreateDevEnum *pDevEnum = NULL;
	HRESULT hr = CoCreateInstance(CLSID_SystemDeviceEnum,
		NULL,
		CLSCTX_INPROC_SERVER,
		IID_PPV_ARGS(&pDevEnum));

	if (SUCCEEDED(hr))
	{
		IEnumMoniker *pEnum = NULL;
		hr = pDevEnum->CreateClassEnumerator(CLSID_VideoInputDeviceCategory, &pEnum, 0);

		if (hr != S_FALSE)
		{
			IMoniker *pMoniker = NULL;
			while ((pEnum->Next(1, &pMoniker, NULL) == S_OK) && !(pBFilter))
			{
				IPropertyBag *pPropBag = NULL;
				hr = pMoniker->BindToStorage(0, 0, IID_PPV_ARGS(&pPropBag));

				if (FAILED(hr))
				{
					pMoniker->Release();
					continue;
				}

				VARIANT var;
				VariantInit(&var);

				if (deviceName.length() == 0) {
					hr = pPropBag->Read(L"DevicePath", &var, 0);
					if (SUCCEEDED(hr))
					{
						std::wstring _DevicePath = (const wchar_t *)var.bstrVal;
						VariantClear(&var);
						devicePath = _DevicePath;

						hr = pMoniker->BindToObject(0, 0, IID_IBaseFilter, (void **)&pBFilter);
					}

				}
				else {
					hr = pPropBag->Read(L"DevicePath", &var, 0);
					if (SUCCEEDED(hr))
					{
						std::wstring _DevicePath = (const wchar_t *)var.bstrVal;
						VariantClear(&var);

						if (deviceName.compare(_DevicePath) == 0)
						{
							devicePath = deviceName;
							hr = pMoniker->BindToObject(0, 0, IID_IBaseFilter, (void **)&pBFilter);
						}

					}

				}

				pPropBag->Release();
				pMoniker->Release();
			}

		}
		pDevEnum->Release();
	}

	return pBFilter;
}

PA_Picture CaptureMan::copyImage() {

	if (isConfigured) {

		if (!USE_VMR9) {

			AM_MEDIA_TYPE am_media_type;
			ZeroMemory(&am_media_type, sizeof(am_media_type));

			sampleGrabber->GetConnectedMediaType(&am_media_type);
			VIDEOINFOHEADER *pVideoInfoHeader = (VIDEOINFOHEADER *)am_media_type.pbFormat;

			long size = am_media_type.lSampleSize;
			std::vector<uint8_t> buf(size);

			sampleGrabber->GetCurrentBuffer(&size, (long *)&buf[0]);

			BITMAPFILEHEADER bmphdr;
			memset(&bmphdr, 0, sizeof(bmphdr));
			bmphdr.bfType = ('M' << 8) | 'B';
			bmphdr.bfSize = sizeof(bmphdr) + sizeof(BITMAPINFOHEADER) + size;
			bmphdr.bfOffBits = sizeof(bmphdr) + sizeof(BITMAPINFOHEADER);

			std::vector<uint8_t> bytes(sizeof(bmphdr) + sizeof(BITMAPINFOHEADER) + size);
			memmove((char *)&bytes[0], &bmphdr, sizeof(bmphdr));
			memmove((char *)&bytes[sizeof(bmphdr)], &pVideoInfoHeader->bmiHeader, sizeof(BITMAPINFOHEADER));
			memmove((char *)&bytes[sizeof(bmphdr) + sizeof(BITMAPINFOHEADER)], &buf[0], size);

			return PA_CreatePicture(&bytes[0], bytes.size());
		}
		else {

			BYTE *lpDib = NULL;
			HRESULT hr = windowlessControl9->GetCurrentImage(&lpDib);
			if (SUCCEEDED(hr))
			{
				BITMAPINFOHEADER *bmi = reinterpret_cast<BITMAPINFOHEADER*>(lpDib);
				int w = abs(bmi->biWidth);
				int	h = abs(bmi->biHeight);
				bmi->biBitCount;
				unsigned char*p = lpDib + bmi->biSize;
				if ((bmi->biCompression == BI_RGB) && (bmi->biPlanes == 1)) {
					if ((bmi->biBitCount == 24) || (bmi->biBitCount == 32)) {
						size_t size = w * h * ((bmi->biBitCount == 24) ? 3 : 4);

						BITMAPFILEHEADER bmphdr;
						memset(&bmphdr, 0, sizeof(bmphdr));
						bmphdr.bfType = ('M' << 8) | 'B';
						bmphdr.bfSize = sizeof(bmphdr) + sizeof(BITMAPINFOHEADER) + size;
						bmphdr.bfOffBits = sizeof(bmphdr) + sizeof(BITMAPINFOHEADER);

						std::vector<uint8_t> bytes(sizeof(bmphdr) + sizeof(BITMAPINFOHEADER) + size);
						memmove((char *)&bytes[0], &bmphdr, sizeof(bmphdr));
						memmove((char *)&bytes[sizeof(bmphdr)], lpDib, sizeof(BITMAPINFOHEADER));
						memmove((char *)&bytes[sizeof(bmphdr) + sizeof(BITMAPINFOHEADER)], p, size);

						return PA_CreatePicture(&bytes[0], bytes.size());
					}

				}

				CoTaskMemFree(lpDib);
			}
		}
	}

	char _buf[1];
	return PA_CreatePicture(_buf, 0);
}

void CaptureMan::update(
	PA_long32 w,
	PA_long32 x,
	PA_long32 y,
	PA_long32 width,
	PA_long32 height,
	bool hidden) {

	//captureGraphBuilder->SetOutputFileName

	if (isConfigured) {
		HWND _windowRef = (HWND)PA_GetHWND(reinterpret_cast<PA_WindowRef>(w));

		if (_windowRef)
		{
			if (windowRef != w) {
				windowRef = w;
				if (!USE_VMR9) {
					videoWindow->put_Owner((OAHWND)_windowRef);
				}
				else {
					windowlessControl9->SetVideoClippingWindow(_windowRef);
				}
			}
		}

		if (!USE_VMR9) {

			AM_MEDIA_TYPE am_media_type;
			ZeroMemory(&am_media_type, sizeof(am_media_type));

			sampleGrabber->GetConnectedMediaType(&am_media_type);
			VIDEOINFOHEADER *pVideoInfoHeader = (VIDEOINFOHEADER *)am_media_type.pbFormat;

			double h = pVideoInfoHeader->bmiHeader.biHeight;
			double w = pVideoInfoHeader->bmiHeader.biWidth;
			double _width = width;
			double _height = height;

			if (w > h) {

				long rationalHeight = (_width * (h / w));
				if (height > rationalHeight) {
					y += ((height - rationalHeight) / 2);
					height = rationalHeight;
				}
				else {
					x += ((width - (_height * (w / h))) / 2);
					width = (_height * (w / h));
				}

			}

			else {

				long rationalWidth = (_height * (w / h));
				if (width > rationalWidth) {
					x += ((width - rationalWidth) / 2);
					width = rationalWidth;
				}
				else {
					y += ((height - (_width * (h / w))) / 2);
					height = (_width * (h / w));
				}
			}
			
			videoWindow->SetWindowPosition(x, y, width, height);
			if (hidden) {
				videoWindow->put_Visible(OAFALSE);
				videoWindow->put_AutoShow(OAFALSE);
			}
			else {
				videoWindow->put_Visible(OAFALSE);
				videoWindow->put_AutoShow(OATRUE);
			}
		}
		else {
			RECT rect;
			rect.top = y;
			rect.bottom = y + height;
			rect.left = x;
			rect.right = x + width;
			windowlessControl9->SetVideoPosition(NULL, &rect);
		}
	}
}

void CaptureMan::setup(const wchar_t *deviceName,
	PA_long32 w,
	PA_long32 x,
	PA_long32 y,
	PA_long32 width,
	PA_long32 height,
	const wchar_t *file) {

	if (!isConfigured) {
	
		HWND _windowRef = (HWND)PA_GetHWND(reinterpret_cast<PA_WindowRef>(w));

		ICaptureGraphBuilder2 *pCapture = NULL;

		ISampleGrabber *pGrabber = NULL;
		IVMRWindowlessControl9 *pVMR = NULL;
		IVMRFilterConfig9 *pConfig = NULL;
		IBaseFilter *pVmr9 = NULL;

		IBaseFilter *pGrabberFilter = NULL;
		IBaseFilter *pDeviceFilter = capture_getDeviceForName(deviceName, devicePath);

		IGraphBuilder *pGraph = NULL;
		HRESULT hr = CoCreateInstance(CLSID_FilterGraph, NULL,
			CLSCTX_INPROC_SERVER,
			IID_IGraphBuilder,
			(void **)&pGraph);
		if (SUCCEEDED(hr)) {

			hr = CoCreateInstance(CLSID_CaptureGraphBuilder2,
				NULL,
				CLSCTX_INPROC_SERVER,
				IID_ICaptureGraphBuilder2,
				(void**)&pCapture);

			if (SUCCEEDED(hr)) {

				if (USE_VMR9) {

					hr = CoCreateInstance(CLSID_VideoMixingRenderer9,
						NULL,
						CLSCTX_INPROC_SERVER,
						IID_IBaseFilter,
						(void**)&pVmr9);

					if (SUCCEEDED(hr)) {
						hr = pGraph->AddFilter(pVmr9, L"VMR-9");
						if (SUCCEEDED(hr)) {
							hr = pVmr9->QueryInterface(IID_IVMRFilterConfig9, (void**)&pConfig);
							if (SUCCEEDED(hr))
							{
								hr = pConfig->SetRenderingMode(VMR9Mode_Windowless);
							}
							hr = pVmr9->QueryInterface(IID_IVMRWindowlessControl9, (void **)&pVMR);
							if (SUCCEEDED(hr)) {
								hr = pVMR->SetAspectRatioMode(VMR9ARMode_LetterBox);
								if (_windowRef)
								{
									windowRef = w;
									hr = pVMR->SetVideoClippingWindow(_windowRef);
									RECT rect;
									rect.top = y;
									rect.bottom = y + height;
									rect.left = x;
									rect.right = x + width;
									hr = pVMR->SetVideoPosition(NULL, &rect);
								}
							}
						}
					}
				}
				else {

					hr = CoCreateInstance(CLSID_SampleGrabber,
						NULL,
						CLSCTX_INPROC_SERVER,
						IID_PPV_ARGS(&pGrabberFilter));
					if (SUCCEEDED(hr)) {
						hr = pGrabberFilter->QueryInterface(IID_ISampleGrabber, (void **)&pGrabber);
						if (SUCCEEDED(hr)) {
							//Set the Media Type
							AM_MEDIA_TYPE mt;
							ZeroMemory(&mt, sizeof(mt));
							mt.majortype = MEDIATYPE_Video;
							mt.subtype = MEDIASUBTYPE_RGB24;
							mt.formattype = FORMAT_VideoInfo;
							hr = pGrabber->SetMediaType(&mt);
							if (SUCCEEDED(hr)) {
								hr = pGraph->AddFilter(pGrabberFilter, L"Sample Grabber");

							}
						}
					}
				}

				if (SUCCEEDED(hr)) {

					hr = pCapture->SetFiltergraph(pGraph);

					if (SUCCEEDED(hr)) {

						IMediaControl *pMControl = NULL;
						hr = pGraph->QueryInterface(IID_IMediaControl, (void **)&pMControl);

						if (SUCCEEDED(hr)) {

							hr = pGraph->AddFilter(pDeviceFilter, L"Device Filter");

							if (SUCCEEDED(hr)) {

								hr = pCapture->FindInterface(&PIN_CATEGORY_CAPTURE, &MEDIATYPE_Video,
									pDeviceFilter, IID_IAMVideoControl, (void**)&videoControl);

								if (SUCCEEDED(hr)) {

									IPin* pin = NULL;
									long caps = 0;

									hr = pCapture->FindPin(
										pDeviceFilter, PINDIR_OUTPUT, &PIN_CATEGORY_CAPTURE, NULL, FALSE, 0, &pin);
									if (SUCCEEDED(hr)) {
										hr = videoControl->GetCaps(pin, &caps);
										if (SUCCEEDED(hr))
										{
											if ((caps & VideoControlFlag_FlipVertical) > 0)
												caps = caps & ~(VideoControlFlag_FlipVertical);
											if ((caps & VideoControlFlag_FlipHorizontal) != 0)
												caps = caps & ~(VideoControlFlag_FlipHorizontal);

											//videoControl->SetMode(pin, caps);
										}
										pin->Release();
									}

								}

								IFileSinkFilter *pSink = NULL;
								IBaseFilter *pFileOut = NULL;

								if (file) {

									hr = pCapture->SetOutputFileName(&MEDIASUBTYPE_Avi,
										file, &pFileOut, &pSink);

									if (SUCCEEDED(hr)) {

										filePath = std::wstring(file);
										hr = pCapture->RenderStream(&PIN_CATEGORY_CAPTURE,
											&MEDIATYPE_Video,
											pDeviceFilter,
											NULL,
											pFileOut);
									}

								}

								if (USE_VMR9) {
									hr = pCapture->RenderStream(NULL,
										NULL,
										pDeviceFilter,
										pGrabberFilter,
										pVmr9);

								}
								else {
									hr = pCapture->RenderStream(&PIN_CATEGORY_PREVIEW,
										&MEDIATYPE_Video,
										pDeviceFilter,
										pGrabberFilter,
										NULL);
								}

								if (SUCCEEDED(hr)) {
									IVideoWindow *pVWindow = NULL;
									hr = pGraph->QueryInterface(IID_IVideoWindow, (void **)&pVWindow);
									if (SUCCEEDED(hr)) {

										if (_windowRef)
										{
											windowRef = w;

											if (!USE_VMR9) {

												AM_MEDIA_TYPE am_media_type;
												ZeroMemory(&am_media_type, sizeof(am_media_type));

												pGrabber->GetConnectedMediaType(&am_media_type);
												VIDEOINFOHEADER *pVideoInfoHeader = (VIDEOINFOHEADER *)am_media_type.pbFormat;

												double h = pVideoInfoHeader->bmiHeader.biHeight;
												double w = pVideoInfoHeader->bmiHeader.biWidth;
												double _width = width;
												double _height = height;

												if (w > h) {

													long rationalHeight = (_width * (h / w));
													if (height > rationalHeight) {
														y += ((height - rationalHeight) / 2);
														height = rationalHeight;
													}
													else {
														x += ((width - (_height * (w / h))) / 2);
														width = (_height * (w / h));
													}

												}

												else {

													long rationalWidth = (_height * (w / h));
													if (width > rationalWidth) {
														x += ((width - rationalWidth) / 2);
														width = rationalWidth;
													}
													else {
														y += ((height - (_width * (h / w))) / 2);
														height = (_width * (h / w));
													}
												}

												pVWindow->put_Owner((OAHWND)_windowRef);
												pVWindow->put_Visible(OAFALSE);
												pVWindow->put_AutoShow(OATRUE);
												pVWindow->SetWindowPosition(x, y, width, height);
												pVWindow->HideCursor(OAFALSE);
												pVWindow->put_WindowStyle(WS_CHILD | WS_CLIPCHILDREN);
											}

											deviceFilter = pDeviceFilter;
											mediaControl = pMControl;
											videoWindow = pVWindow;
											graphBuilder = pGraph;
											grabberFilter = pGrabberFilter;
											sampleGrabber = pGrabber;
											captureGraphBuilder = pCapture;

											windowlessControl9 = pVMR;
											filterConfig9 = pConfig;
											vmr9Filter = pVmr9;

											mediaControl->Pause();

											if (!USE_VMR9) {
												sampleGrabber->SetBufferSamples(FALSE);
											}

											isConfigured = true;

										}

									}//QueryInterface

								}

							}//AddFilter (Device Filter)

						}//pMControl

					}//SetFiltergraph

				}//AddFilter (Sample Grabber)

			}

		}

	}

}

#endif
